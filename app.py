import streamlit as st
import graphviz
import os
import google.generativeai as genai

from data import TOPOLOGY
from logic import CausalInferenceEngine, Alarm, simulate_cascade_failure
from network_ops import run_diagnostic_simulation

# --- ãƒšãƒ¼ã‚¸è¨­å®š ---
st.set_page_config(page_title="Antigravity Live", page_icon="âš¡", layout="wide")

# --- é–¢æ•°: ãƒˆãƒãƒ­ã‚¸ãƒ¼å›³ã®ç”Ÿæˆ ---
def render_topology(alarms, root_cause_node):
    graph = graphviz.Digraph()
    graph.attr(rankdir='TB')
    graph.attr('node', shape='box', style='rounded,filled', fontname='Helvetica')
    
    alarmed_ids = {a.device_id for a in alarms}
    
    for node_id, node in TOPOLOGY.items():
        color = "#e8f5e9" # Default Green
        penwidth = "1"
        fontcolor = "black"
        label = f"{node_id}\n({node.type})"
        
        if root_cause_node and node_id == root_cause_node.id:
            color = "#ffcdd2" # Root Cause Red
            penwidth = "3"
            label += "\n[ROOT CAUSE]"
        elif node_id in alarmed_ids:
            color = "#fff9c4" # Alarm Yellow
        
        graph.node(node_id, label=label, fillcolor=color, color='black', penwidth=penwidth, fontcolor=fontcolor)
    
    for node_id, node in TOPOLOGY.items():
        if node.parent_id:
            graph.edge(node.parent_id, node_id)
            parent_node = TOPOLOGY.get(node.parent_id)
            if parent_node and parent_node.redundancy_group:
                partners = [n.id for n in TOPOLOGY.values() 
                           if n.redundancy_group == parent_node.redundancy_group and n.id != parent_node.id]
                for partner_id in partners:
                    graph.edge(partner_id, node_id)
    return graph

# --- é–¢æ•°: Configè‡ªå‹•èª­ã¿è¾¼ã¿ ---
def load_config_by_id(device_id):
    path = f"configs/{device_id}.txt"
    if os.path.exists(path):
        try:
            with open(path, "r", encoding="utf-8") as f:
                return f.read()
        except Exception:
            return None
    return None

# --- UIæ§‹ç¯‰ ---
st.title("âš¡ Antigravity AI Agent (Live Demo)")

api_key = None
if "GOOGLE_API_KEY" in st.secrets:
    api_key = st.secrets["GOOGLE_API_KEY"]
else:
    api_key = os.environ.get("GOOGLE_API_KEY")

with st.sidebar:
    st.header("âš¡ é‹ç”¨ãƒ¢ãƒ¼ãƒ‰é¸æŠ")
    
    # ã‚·ãƒŠãƒªã‚ªå®šç¾© (ãƒªã‚¹ãƒˆã§è¦‹ã‚„ã™ãæ•´ç†)
    scenario_options = (
        "æ­£å¸¸ç¨¼åƒ",
        # --- åºƒåŸŸãƒ»é€£æºéšœå®³ ---
        "1. [åºƒåŸŸ] WANå…¨å›ç·šæ–­",
        "2. [åºƒåŸŸ] FWç‰‡ç³»éšœå®³",
        "3. [åºƒåŸŸ] L2SWã‚µã‚¤ãƒ¬ãƒ³ãƒˆéšœå®³",
        # --- WAN Router å€‹åˆ¥ ---
        "4. [WAN] BGPãƒ«ãƒ¼ãƒˆãƒ•ãƒ©ãƒƒãƒ”ãƒ³ã‚°",
        "5. [WAN] FANæ•…éšœ",
        "6. [WAN] é›»æºæ•…éšœ",
        "7. [WAN] ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯",
        # --- FW å€‹åˆ¥ ---
        "8. [FW] FANæ•…éšœ",
        "9. [FW] é›»æºæ•…éšœ",
        "10. [FW] ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯",
        # --- L2SW å€‹åˆ¥ ---
        "11. [L2SW] FANæ•…éšœ",
        "12. [L2SW] é›»æºæ•…éšœ",
        "13. [L2SW] ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯",
        # --- Live ---
        "99. [Live] Ciscoå®Ÿæ©Ÿè¨ºæ–­"
    )
    
    selected_scenario = st.radio("ã‚·ãƒŠãƒªã‚ªã‚’é¸æŠ:", scenario_options)
    
    st.markdown("---")
    if api_key:
        st.success("API Connected")
    else:
        st.warning("API Key Missing")
        user_key = st.text_input("Google API Key", type="password")
        if user_key: api_key = user_key

# ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ç®¡ç†
if "current_scenario" not in st.session_state:
    st.session_state.current_scenario = "æ­£å¸¸ç¨¼åƒ"
    st.session_state.messages = []
    st.session_state.chat_session = None 
    st.session_state.live_result = None
    st.session_state.trigger_analysis = False

if st.session_state.current_scenario != selected_scenario:
    st.session_state.current_scenario = selected_scenario
    st.session_state.messages = []
    st.session_state.chat_session = None
    st.session_state.live_result = None
    st.session_state.trigger_analysis = False
    st.rerun()

# --- ã‚¢ãƒ©ãƒ¼ãƒ ç”Ÿæˆ (ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³) ---
alarms = []

# æ–‡å­—åˆ—åˆ¤å®šã§ã‚¢ãƒ©ãƒ¼ãƒ ã‚’æŒ¯ã‚Šåˆ†ã‘
if "WANå…¨å›ç·šæ–­" in selected_scenario:
    alarms = simulate_cascade_failure("WAN_ROUTER_01", TOPOLOGY)
elif "FWç‰‡ç³»éšœå®³" in selected_scenario:
    alarms = [Alarm("FW_01_PRIMARY", "Heartbeat Loss", "WARNING")]
elif "L2SWã‚µã‚¤ãƒ¬ãƒ³ãƒˆéšœå®³" in selected_scenario:
    alarms = [Alarm("AP_01", "Connection Lost", "CRITICAL"), Alarm("AP_02", "Connection Lost", "CRITICAL")]

# --- WAN Router å€‹åˆ¥éšœå®³ ---
elif "[WAN]" in selected_scenario:
    msg = "Hardware Error"
    sev = "CRITICAL"
    if "BGP" in selected_scenario:
        msg = "BGP Neighbor Flapping"
        sev = "WARNING"
    elif "ãƒ¡ãƒ¢ãƒª" in selected_scenario:
        msg = "Memory High Utilization"
        sev = "WARNING"
    alarms = [Alarm("WAN_ROUTER_01", msg, sev)]

# --- FW å€‹åˆ¥éšœå®³ ---
elif "[FW]" in selected_scenario:
    msg = "Hardware Alert"
    sev = "CRITICAL"
    if "ãƒ¡ãƒ¢ãƒª" in selected_scenario:
        msg = "Memory High"
        sev = "WARNING"
    alarms = [Alarm("FW_01_PRIMARY", msg, sev)]

# --- L2SW å€‹åˆ¥éšœå®³ ---
elif "[L2SW]" in selected_scenario:
    msg = "Environment Alert"
    sev = "CRITICAL"
    if "ãƒ¡ãƒ¢ãƒª" in selected_scenario:
        msg = "Memory Threshold Exceeded"
        sev = "WARNING"
    alarms = [Alarm("L2_SW_01", msg, sev)]

root_cause = None
inference_result = None
reason = ""

if alarms:
    engine = CausalInferenceEngine(TOPOLOGY)
    res = engine.analyze_alarms(alarms)
    root_cause = res.root_cause_node
    reason = res.root_cause_reason

# --- ãƒ¡ã‚¤ãƒ³ç”»é¢ ---
col1, col2 = st.columns([1, 1])

# å·¦ã‚«ãƒ©ãƒ 
with col1:
    st.subheader("Network Status")
    st.graphviz_chart(render_topology(alarms, root_cause), use_container_width=True)
    
    if root_cause:
        st.markdown(f'<div style="color:#d32f2f;background:#fdecea;padding:10px;border-radius:5px;">ğŸš¨ ç·Šæ€¥ã‚¢ãƒ©ãƒ¼ãƒˆï¼š{root_cause.id} ãƒ€ã‚¦ãƒ³</div>', unsafe_allow_html=True)
        st.caption(f"ç†ç”±: {reason}")
    
    is_live_mode = ("[Live]" in selected_scenario)
    
    if is_live_mode or root_cause:
        st.markdown("---")
        st.info("ğŸ›  **è‡ªå¾‹èª¿æŸ»ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ**")
        
        # ãƒœã‚¿ãƒ³: è¨ºæ–­å®Ÿè¡Œ
        if st.button("ğŸš€ è¨ºæ–­å®Ÿè¡Œ (Auto-Diagnostic)", type="primary"):
            if not api_key:
                st.error("API Key Required")
            else:
                with st.status("Agent Operating...", expanded=True) as status:
                    st.write("ğŸ”Œ Establishing Connection / Generating Simulation...")
                    
                    # APIã‚­ãƒ¼ã‚’æ¸¡ã—ã¦AIãƒ­ã‚°ç”Ÿæˆã‚’å®Ÿè¡Œ
                    res = run_diagnostic_simulation(selected_scenario, api_key)
                    
                    st.session_state.live_result = res
                    
                    if res["status"] == "SUCCESS":
                        st.write("âœ… Data Acquired.")
                        st.write("ğŸ§¹ Sanitizing Sensitive Information...")
                        status.update(label="Complete!", state="complete", expanded=False)
                    else:
                        st.write("âŒ Connection Failed / Simulation Error.")
                        status.update(label="Target Unreachable", state="error", expanded=False)
                    
                    # ã‚¨ãƒ©ãƒ¼ã®åŸå› ã ã£ãŸã‚¤ãƒ³ãƒ‡ãƒ³ãƒˆã‚’ä¿®æ­£ã—ã¾ã—ãŸ
                    st.session_state.trigger_analysis = True
                    st.rerun()

        if st.session_state.live_result:
            res = st.session_state.live_result
            if res["status"] == "SUCCESS":
                st.success("ğŸ›¡ï¸ **Data Sanitized**: ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ãƒ»IPã‚¢ãƒ‰ãƒ¬ã‚¹ã‚’ãƒã‚¹ã‚¯å‡¦ç†ã—ã¾ã—ãŸã€‚")
                with st.expander("ğŸ“„ å–å¾—ãƒ­ã‚° (Sanitized View)", expanded=True):
                    st.code(res["sanitized_log"], language="text")
            else:
                st.error(f"è¨ºæ–­çµæœ: {res['error']}")

# å³ã‚«ãƒ©ãƒ 
with col2:
    st.subheader("AI Analyst Report")
    if not api_key: st.stop()

    should_start_chat = (st.session_state.chat_session is None) and (selected_scenario != "æ­£å¸¸ç¨¼åƒ")
    
    if should_start_chat:
        genai.configure(api_key=api_key)
        model = genai.GenerativeModel("gemini-2.0-flash", generation_config={"temperature": 0.0})
        
        system_prompt = ""
        if st.session_state.live_result:
            live_data = st.session_state.live_result
            log_content = live_data.get('sanitized_log') or f"Error: {live_data.get('error')}"
            system_prompt = f"è¨ºæ–­çµæœã«åŸºã¥ããƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆã›ã‚ˆã€‚\nã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {live_data['status']}\nãƒ­ã‚°: {log_content}"
        elif root_cause:
            conf = load_config_by_id(root_cause.id)
            system_prompt = f"éšœå®³å ±å‘Š: {root_cause.id}ã€‚ç†ç”±: {reason}ã€‚"
            if conf: system_prompt += f"\nConfig:\n{conf}"
        
        if system_prompt:
            chat = model.start_chat(history=[{"role": "user", "parts": [system_prompt]}])
            try:
                with st.spinner("Analyzing..."):
                    res = chat.send_message("çŠ¶æ³å ±å‘Šã‚’ãŠé¡˜ã„ã—ã¾ã™ã€‚")
                    st.session_state.chat_session = chat
                    st.session_state.messages.append({"role": "assistant", "content": res.text})
            except Exception as e: st.error(str(e))

    if st.session_state.trigger_analysis and st.session_state.chat_session:
        live_data = st.session_state.live_result
        log_content = live_data.get('sanitized_log') or f"Error: {live_data.get('error')}"
        
        prompt = f"""
        è¨ºæ–­ã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œã—ã¾ã—ãŸã€‚ä»¥ä¸‹ã®çµæœã«åŸºã¥ãã€ãƒã‚¯ã‚¹ãƒˆã‚¢ã‚¯ã‚·ãƒ§ãƒ³å®Ÿè¡Œãƒ¬ãƒãƒ¼ãƒˆã€ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚
        
        ã€è¨ºæ–­ãƒ‡ãƒ¼ã‚¿ã€‘
        ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {live_data['status']}
        ãƒ­ã‚°: {log_content}
        
        ã€å‡ºåŠ›è¦ä»¶ã€‘
        1. æ¥ç¶šçµæœ (æˆåŠŸ/å¤±æ•—)
        2. ãƒ­ã‚°åˆ†æ (ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹çŠ¶æ…‹ã€ãƒ«ãƒ¼ãƒˆæƒ…å ±ã€ç’°å¢ƒå¤‰æ•°ãªã©)
        3. æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³
        """
        st.session_state.messages.append({"role": "user", "content": "è¨ºæ–­çµæœã‚’åˆ†æã—ã¦ãã ã•ã„ã€‚"})
        
        with st.spinner("Analyzing Diagnostic Data..."):
            try:
                res = st.session_state.chat_session.send_message(prompt)
                st.session_state.messages.append({"role": "assistant", "content": res.text})
            except Exception as e: st.error(str(e))
        
        st.session_state.trigger_analysis = False
        st.rerun()

    chat_container = st.container(height=600)
    with chat_container:
        for msg in st.session_state.messages:
            if "è¨ºæ–­çµæœã«åŸºã¥ã" in msg["content"]: continue
            with st.chat_message(msg["role"]): st.markdown(msg["content"])

    if prompt := st.chat_input("è³ªå•..."):
        st.session_state.messages.append({"role": "user", "content": prompt})
        with chat_container:
            with st.chat_message("user"): st.markdown(prompt)
        if st.session_state.chat_session:
            with chat_container:
                with st.chat_message("assistant"):
                    with st.spinner("Thinking..."):
                        res = st.session_state.chat_session.send_message(prompt)
                        st.markdown(res.text)
                        st.session_state.messages.append({"role": "assistant", "content": res.text})
